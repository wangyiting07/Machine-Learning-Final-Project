{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing data\n",
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 11.013380\n",
      "Train Epoch: 0 [2000/50000 (4%)]\tLoss: 1.282363\n",
      "Train Epoch: 0 [4000/50000 (8%)]\tLoss: 0.804064\n",
      "Train Epoch: 0 [6000/50000 (12%)]\tLoss: 0.628302\n",
      "Train Epoch: 0 [8000/50000 (16%)]\tLoss: 0.440960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [10000/50000 (20%)]\tLoss: 0.409299\n",
      "Train Epoch: 0 [12000/50000 (24%)]\tLoss: 0.342904\n",
      "Train Epoch: 0 [14000/50000 (28%)]\tLoss: 0.251383\n",
      "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 0.321161\n",
      "Train Epoch: 0 [18000/50000 (36%)]\tLoss: 0.214895\n",
      "Train Epoch: 0 [20000/50000 (40%)]\tLoss: 0.348850\n",
      "Train Epoch: 0 [22000/50000 (44%)]\tLoss: 0.187071\n",
      "Train Epoch: 0 [24000/50000 (48%)]\tLoss: 0.261887\n",
      "Train Epoch: 0 [26000/50000 (52%)]\tLoss: 0.406760\n",
      "Train Epoch: 0 [28000/50000 (56%)]\tLoss: 0.236154\n",
      "Train Epoch: 0 [30000/50000 (60%)]\tLoss: 0.302386\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 0.254083\n",
      "Train Epoch: 0 [34000/50000 (68%)]\tLoss: 0.138279\n",
      "Train Epoch: 0 [36000/50000 (72%)]\tLoss: 0.195485\n",
      "Train Epoch: 0 [38000/50000 (76%)]\tLoss: 0.229271\n",
      "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 0.181492\n",
      "Train Epoch: 0 [42000/50000 (84%)]\tLoss: 0.155420\n",
      "Train Epoch: 0 [44000/50000 (88%)]\tLoss: 0.202699\n",
      "Train Epoch: 0 [46000/50000 (92%)]\tLoss: 0.167295\n",
      "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 0.059939\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.210319\n",
      "Train Epoch: 1 [2000/50000 (4%)]\tLoss: 0.182729\n",
      "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 0.131681\n",
      "Train Epoch: 1 [6000/50000 (12%)]\tLoss: 0.084604\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 0.120425\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 0.146285\n",
      "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 0.188757\n",
      "Train Epoch: 1 [14000/50000 (28%)]\tLoss: 0.096355\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.105137\n",
      "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 0.155934\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 0.107310\n",
      "Train Epoch: 1 [22000/50000 (44%)]\tLoss: 0.161558\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.176631\n",
      "Train Epoch: 1 [26000/50000 (52%)]\tLoss: 0.183718\n",
      "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 0.115707\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 0.092547\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.132161\n",
      "Train Epoch: 1 [34000/50000 (68%)]\tLoss: 0.126380\n",
      "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 0.111715\n",
      "Train Epoch: 1 [38000/50000 (76%)]\tLoss: 0.117927\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.152968\n",
      "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 0.155042\n",
      "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 0.099034\n",
      "Train Epoch: 1 [46000/50000 (92%)]\tLoss: 0.100123\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.121969\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.038689\n",
      "Train Epoch: 2 [2000/50000 (4%)]\tLoss: 0.127369\n",
      "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 0.067393\n",
      "Train Epoch: 2 [6000/50000 (12%)]\tLoss: 0.057462\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 0.067222\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 0.118651\n",
      "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 0.113432\n",
      "Train Epoch: 2 [14000/50000 (28%)]\tLoss: 0.086663\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.045123\n",
      "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 0.051850\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.149455\n",
      "Train Epoch: 2 [22000/50000 (44%)]\tLoss: 0.186855\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.119591\n",
      "Train Epoch: 2 [26000/50000 (52%)]\tLoss: 0.064638\n",
      "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 0.116744\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 0.108286\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.108406\n",
      "Train Epoch: 2 [34000/50000 (68%)]\tLoss: 0.069798\n",
      "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 0.107309\n",
      "Train Epoch: 2 [38000/50000 (76%)]\tLoss: 0.028471\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.125283\n",
      "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 0.074797\n",
      "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 0.043995\n",
      "Train Epoch: 2 [46000/50000 (92%)]\tLoss: 0.105026\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.042649\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.050600\n",
      "Train Epoch: 3 [2000/50000 (4%)]\tLoss: 0.077887\n",
      "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 0.046822\n",
      "Train Epoch: 3 [6000/50000 (12%)]\tLoss: 0.040269\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 0.096788\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 0.084306\n",
      "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 0.024166\n",
      "Train Epoch: 3 [14000/50000 (28%)]\tLoss: 0.031662\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.062593\n",
      "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 0.100022\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 0.034071\n",
      "Train Epoch: 3 [22000/50000 (44%)]\tLoss: 0.076748\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.094390\n",
      "Train Epoch: 3 [26000/50000 (52%)]\tLoss: 0.077150\n",
      "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 0.111196\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 0.055759\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.051456\n",
      "Train Epoch: 3 [34000/50000 (68%)]\tLoss: 0.174676\n",
      "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 0.044894\n",
      "Train Epoch: 3 [38000/50000 (76%)]\tLoss: 0.122079\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.048471\n",
      "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 0.134542\n",
      "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 0.057971\n",
      "Train Epoch: 3 [46000/50000 (92%)]\tLoss: 0.024856\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.050890\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.025856\n",
      "Train Epoch: 4 [2000/50000 (4%)]\tLoss: 0.029673\n",
      "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 0.059842\n",
      "Train Epoch: 4 [6000/50000 (12%)]\tLoss: 0.068782\n",
      "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 0.036689\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.126056\n",
      "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 0.057581\n",
      "Train Epoch: 4 [14000/50000 (28%)]\tLoss: 0.050241\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.064216\n",
      "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 0.059427\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.034007\n",
      "Train Epoch: 4 [22000/50000 (44%)]\tLoss: 0.034920\n",
      "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 0.102362\n",
      "Train Epoch: 4 [26000/50000 (52%)]\tLoss: 0.042635\n",
      "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 0.097686\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 0.038758\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.070010\n",
      "Train Epoch: 4 [34000/50000 (68%)]\tLoss: 0.095011\n",
      "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 0.054999\n",
      "Train Epoch: 4 [38000/50000 (76%)]\tLoss: 0.035473\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 0.051701\n",
      "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 0.057098\n",
      "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 0.046396\n",
      "Train Epoch: 4 [46000/50000 (92%)]\tLoss: 0.062295\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.030197\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.034176\n",
      "Train Epoch: 5 [2000/50000 (4%)]\tLoss: 0.025575\n",
      "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 0.064824\n",
      "Train Epoch: 5 [6000/50000 (12%)]\tLoss: 0.031578\n",
      "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 0.036354\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 0.026581\n",
      "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 0.042028\n",
      "Train Epoch: 5 [14000/50000 (28%)]\tLoss: 0.035370\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.035014\n",
      "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 0.082391\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 0.039619\n",
      "Train Epoch: 5 [22000/50000 (44%)]\tLoss: 0.022436\n",
      "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 0.036021\n",
      "Train Epoch: 5 [26000/50000 (52%)]\tLoss: 0.031766\n",
      "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 0.017455\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 0.014803\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.053493\n",
      "Train Epoch: 5 [34000/50000 (68%)]\tLoss: 0.077969\n",
      "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 0.026633\n",
      "Train Epoch: 5 [38000/50000 (76%)]\tLoss: 0.054492\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.020023\n",
      "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 0.059912\n",
      "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 0.018585\n",
      "Train Epoch: 5 [46000/50000 (92%)]\tLoss: 0.061306\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.093551\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.022336\n",
      "Train Epoch: 6 [2000/50000 (4%)]\tLoss: 0.035439\n",
      "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 0.019631\n",
      "Train Epoch: 6 [6000/50000 (12%)]\tLoss: 0.051702\n",
      "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 0.029265\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 0.020832\n",
      "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 0.033535\n",
      "Train Epoch: 6 [14000/50000 (28%)]\tLoss: 0.096625\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.019788\n",
      "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 0.063409\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.016248\n",
      "Train Epoch: 6 [22000/50000 (44%)]\tLoss: 0.016738\n",
      "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 0.021930\n",
      "Train Epoch: 6 [26000/50000 (52%)]\tLoss: 0.033190\n",
      "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 0.038720\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 0.010346\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.055264\n",
      "Train Epoch: 6 [34000/50000 (68%)]\tLoss: 0.021028\n",
      "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.018165\n",
      "Train Epoch: 6 [38000/50000 (76%)]\tLoss: 0.016429\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 0.026667\n",
      "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 0.055618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 0.049532\n",
      "Train Epoch: 6 [46000/50000 (92%)]\tLoss: 0.024003\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.010269\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.011450\n",
      "Train Epoch: 7 [2000/50000 (4%)]\tLoss: 0.022849\n",
      "Train Epoch: 7 [4000/50000 (8%)]\tLoss: 0.033952\n",
      "Train Epoch: 7 [6000/50000 (12%)]\tLoss: 0.087190\n",
      "Train Epoch: 7 [8000/50000 (16%)]\tLoss: 0.018392\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 0.015899\n",
      "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 0.037283\n",
      "Train Epoch: 7 [14000/50000 (28%)]\tLoss: 0.033536\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.028209\n",
      "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 0.027750\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 0.037981\n",
      "Train Epoch: 7 [22000/50000 (44%)]\tLoss: 0.032598\n",
      "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.036953\n",
      "Train Epoch: 7 [26000/50000 (52%)]\tLoss: 0.011045\n",
      "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 0.021910\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 0.027834\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.020266\n",
      "Train Epoch: 7 [34000/50000 (68%)]\tLoss: 0.008823\n",
      "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 0.022246\n",
      "Train Epoch: 7 [38000/50000 (76%)]\tLoss: 0.021402\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.011782\n",
      "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 0.049763\n",
      "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 0.029963\n",
      "Train Epoch: 7 [46000/50000 (92%)]\tLoss: 0.016913\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.019869\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.009112\n",
      "Train Epoch: 8 [2000/50000 (4%)]\tLoss: 0.023727\n",
      "Train Epoch: 8 [4000/50000 (8%)]\tLoss: 0.011833\n",
      "Train Epoch: 8 [6000/50000 (12%)]\tLoss: 0.014982\n",
      "Train Epoch: 8 [8000/50000 (16%)]\tLoss: 0.037191\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 0.009376\n",
      "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 0.015062\n",
      "Train Epoch: 8 [14000/50000 (28%)]\tLoss: 0.028095\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.019900\n",
      "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 0.006069\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.032531\n",
      "Train Epoch: 8 [22000/50000 (44%)]\tLoss: 0.023510\n",
      "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 0.040222\n",
      "Train Epoch: 8 [26000/50000 (52%)]\tLoss: 0.008681\n",
      "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 0.018953\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 0.012146\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.047650\n",
      "Train Epoch: 8 [34000/50000 (68%)]\tLoss: 0.007570\n",
      "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 0.024859\n",
      "Train Epoch: 8 [38000/50000 (76%)]\tLoss: 0.014915\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.009267\n",
      "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 0.011420\n",
      "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 0.011769\n",
      "Train Epoch: 8 [46000/50000 (92%)]\tLoss: 0.018110\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.024753\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.009704\n",
      "Train Epoch: 9 [2000/50000 (4%)]\tLoss: 0.019083\n",
      "Train Epoch: 9 [4000/50000 (8%)]\tLoss: 0.005552\n",
      "Train Epoch: 9 [6000/50000 (12%)]\tLoss: 0.010851\n",
      "Train Epoch: 9 [8000/50000 (16%)]\tLoss: 0.004723\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 0.012160\n",
      "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 0.002820\n",
      "Train Epoch: 9 [14000/50000 (28%)]\tLoss: 0.009332\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.018759\n",
      "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 0.008886\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.009449\n",
      "Train Epoch: 9 [22000/50000 (44%)]\tLoss: 0.013702\n",
      "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.005807\n",
      "Train Epoch: 9 [26000/50000 (52%)]\tLoss: 0.013153\n",
      "Train Epoch: 9 [28000/50000 (56%)]\tLoss: 0.011574\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.007744\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.015250\n",
      "Train Epoch: 9 [34000/50000 (68%)]\tLoss: 0.011219\n",
      "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 0.012191\n",
      "Train Epoch: 9 [38000/50000 (76%)]\tLoss: 0.025068\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.011925\n",
      "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 0.026535\n",
      "Train Epoch: 9 [44000/50000 (88%)]\tLoss: 0.054216\n",
      "Train Epoch: 9 [46000/50000 (92%)]\tLoss: 0.021728\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.014625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "data_path = \"./data.mat\"\n",
    "data_raw = loadmat(data_path)\n",
    "\n",
    "train_img = data_raw[\"train_img\"]\n",
    "test_img = data_raw[\"test_img\"]\n",
    "train_lbl = data_raw[\"train_lbl\"]\n",
    "\n",
    "train_img = train_img.astype(np.float64)\n",
    "# train_img -= np.mean(train_img, axis = 0)\n",
    "# train_img /= np.std(train_img, axis = 0)\n",
    "# Max = [None]*784\n",
    "# for i in range(0,784):\n",
    "#     Max[i] = max(train_img[:,i])\n",
    "# train_img = train_img/Max\n",
    "\n",
    "tensor_train_img = torch.from_numpy(train_img) # transform to torch tensors\n",
    "tensor_train_lbl = torch.from_numpy(train_lbl)\n",
    " \n",
    "\n",
    "tensor_train_img = tensor_train_img.type(torch.FloatTensor)\n",
    "tensor_train_lbl = tensor_train_lbl.type(torch.LongTensor)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToPILImage(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "\n",
    "\n",
    "my_trainset = utils.TensorDataset(tensor_train_img,tensor_train_lbl) # create your datset\n",
    "print(\"finish processing data\")\n",
    "\n",
    "def simple_gradient():\n",
    "    # print the gradient of 2x^2 + 5x\n",
    "    x = Variable(torch.ones(2, 2) * 2, requires_grad=True)\n",
    "    z = 2 * (x * x) + 5 * x\n",
    "    # run the backpropagation\n",
    "    z.backward(torch.ones(2, 2))\n",
    "    print(x.grad)\n",
    "\n",
    "\n",
    "def create_nn(batch_size=200, learning_rate=0.001, epochs=10,\n",
    "              log_interval=10):\n",
    "    \n",
    "    my_train_dataloader = utils.DataLoader(my_trainset,batch_size=batch_size, shuffle=True) # create your dataloader\n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.MNIST('../data', train=True, download=False,\n",
    "#                        transform=transforms.Compose([\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                        ])),\n",
    "#         batch_size=batch_size, shuffle=True)\n",
    "#     test_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ])),\n",
    "#         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(28 * 28, 200)\n",
    "            self.fc2 = nn.Linear(200, 200)\n",
    "            self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return F.log_softmax(x)\n",
    "\n",
    "    net = Net()\n",
    "    print(net)\n",
    "\n",
    "    # create a stochastic gradient descent optimizer\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # create a loss function\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # run the main training loop\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(my_train_dataloader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "            data = data.view(-1, 28*28)\n",
    "            target = target.view(200)\n",
    "            optimizer.zero_grad()\n",
    "            net_out = net(data)\n",
    "#             print(\"out: \",net_out)\n",
    "#             print(\"target: \",target)\n",
    "            loss = criterion(net_out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(my_train_dataloader.dataset),\n",
    "                           100. * batch_idx / len(my_train_dataloader), loss.data[0]))\n",
    "\n",
    "#     # run a test loop\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         data, target = Variable(data, volatile=True), Variable(target)\n",
    "#         data = data.view(-1, 28 * 28)\n",
    "#         net_out = net(data)\n",
    "#         # sum up batch loss\n",
    "#         test_loss += criterion(net_out, target).data[0]\n",
    "#         pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "#         correct += pred.eq(target.data).sum()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_opt = 2\n",
    "    if run_opt == 1:\n",
    "        simple_gradient()\n",
    "    elif run_opt == 2:\n",
    "        create_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
